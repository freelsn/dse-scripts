{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ml_header.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run get_data.py\n",
    "benchmarks = ('adpcm_encoder', 'aes', 'ann', 'average', 'decimation', 'fft_fixed', 'fir',\n",
    "              'idct', 'interpolation', 'kasumi', 'qsort', 'snow3g', 'sobel')  # 13\n",
    "gd = GetData('data/ASIC-2-FPGA', benchmarks)\n",
    "gd.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run methods.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run machine_learning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['AREA', 'state', 'FU', 'REG', 'MUX', 'DEC', 'pin_pair',\n",
    "            'net', 'max', 'min', 'ave', 'MISC', 'MEM', 'sim', 'Pmax',\n",
    "            'Pmin', 'Pave', 'Latency', 'BlockMemoryBit', 'DSP', 'Slices']\n",
    "invalid_features = ['Slices', 'Latency']\n",
    "valid_features = [i for i in features if i not in invalid_features]\n",
    "label = 'Slices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute(df, estimator, kind):\n",
    "    # remove attribute columns\n",
    "    data = df[features].copy()\n",
    "    # fix missing data\n",
    "    data = ML.fix_missing_data(data)\n",
    "    # X, y\n",
    "    X, y = ML.separate_feature_label(data, valid_features=valid_features, label=label)\n",
    "    # feature scaling\n",
    "    X = ML.feature_scaling(X)\n",
    "    if kind == 'training':\n",
    "        estimator.fit(X, y)\n",
    "        return estimator\n",
    "    elif kind == 'testing':\n",
    "        y_pred = estimator.predict(X)\n",
    "        data['AREA'] = y_pred\n",
    "        return DirectMapping.main(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_es(data=None, estimator=None, result_fn=None):\n",
    "    scores_all = dict()\n",
    "    for benchmarks_cnt in range(1, len(benchmarks)):\n",
    "        scores = dict()\n",
    "        for benchmarks_train in itertools.combinations(benchmarks, benchmarks_cnt):\n",
    "            benchmarks_test = (i for i in benchmarks if i not in benchmarks_train)\n",
    "            data_train = pd.concat([data[i] for i in benchmarks_train], axis=0, ignore_index=True)\n",
    "            estimator = execute(data_train, estimator, kind='training')\n",
    "            key = ';'.join(list(benchmarks_train))\n",
    "            scores[key] = dict()\n",
    "            for benchmark_test in benchmarks_test:\n",
    "                scores[key][benchmark_test] = execute(data[benchmark_test], estimator, kind='testing')\n",
    "        scores_all[str(benchmarks_cnt)] = scores\n",
    "        \n",
    "    with open(result_fn, 'w') as f:\n",
    "        f.write('train,test,adrs_ave,adrs_max,adrs_ave_rms,adrs_max_rms,hypervolume,dominance,cardinality\\n')\n",
    "        for bench_cnt in scores_all.keys():\n",
    "            for training, testing in scores_all[bench_cnt].items():\n",
    "                for k, v in testing.items():\n",
    "                    f.write(training + ',' + k + ',' + ','.join([f'{i:.4f}' for i in v.values()]) + '\\n')\n",
    "                    \n",
    "    return scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 59min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores_v4_lr = train_es(data=gd.data_v4, estimator=estimators[0], result_fn='es_train_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16h 55min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores_v4_ada = train_es(data=gd.data_v4, estimator=estimators[-2], result_fn='es_v4_ada.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
