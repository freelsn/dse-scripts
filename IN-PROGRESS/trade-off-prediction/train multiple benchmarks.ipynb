{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ml_header.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run get_data.py\n",
    "benchmarks = ('adpcm_encoder', 'average', 'fir')\n",
    "gd = GetData('data/ES', benchmarks, load_fpga_v5=False)\n",
    "gd.main()\n",
    "gd.data_v4.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run methods.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_direct_mapping = {}\n",
    "for i in benchmarks:\n",
    "    print(i)\n",
    "    results_direct_mapping[i] = DirectMapping.main(gd.data_v4[i], plot_figure=True, display_table=True)\n",
    "    print_results(results_direct_mapping[i])\n",
    "    print('=' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run machine_learning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['AREA', 'state', 'FU', 'REG', 'MUX', 'DEC', 'pin_pair',\n",
    "            'net', 'max', 'min', 'ave', 'MISC', 'MEM', 'sim', 'Pmax',\n",
    "            'Pmin', 'Pave', 'Latency', 'BlockMemoryBit', 'DSP', 'Slices']\n",
    "# 'CP_delay',\n",
    "\n",
    "invalid_features = ['Slices', 'Latency']\n",
    "valid_features = [i for i in features if i not in invalid_features]\n",
    "label = 'Slices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine multiple benchmarks\n",
    "benchmark_train = ('fir', 'average')\n",
    "data_train = pd.concat([gd.data_v4[i] for i in benchmark_train], axis=0, ignore_index=True)[features]\n",
    "data_train['Latency'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix missing data\n",
    "data_train = ML.fix_missing_data(data_train)\n",
    "display(data_train.head(2))\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, y\n",
    "X, y = ML.separate_feature_label(data_train, invalid_features=invalid_features, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "X = ML.feature_scaling(X)\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "estimator = RandomForestRegressor()\n",
    "estimator.fit(X, y)\n",
    "for i in np.argsort(estimator.feature_importances_)[::-1]:\n",
    "    print('{}: {:7.3}'.format(valid_features[i], estimator.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "title = 'Learning Curve (Linear Regression)'\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "estimator = ensemble.GradientBoostingRegressor(random_state=42)\n",
    "scores = ML.plot_learning_curve(estimator, title, X, y, ylim=(0.9, 1.01), cv=cv, n_jobs=4)\n",
    "plt.show()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = ML.split_data(data_train, distribution=data_train['Latency'], train_size=1100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ML.separate_feature_label(train_set, invalid_features=['Slices', 'Latency'], label='Slices')\n",
    "print(X.shape)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ML.feature_scaling(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_test = [i for i in benchmarks if i not in benchmark_train]\n",
    "for i in benchmark_test:\n",
    "    data_test = ML.fix_missing_data(gd.data_v4[i][features])\n",
    "    X, y = ML.separate_feature_label(data_test, valid_features=valid_features, label=label)\n",
    "    X = ML.feature_scaling(X)\n",
    "    y_pred = estimator.predict(X)\n",
    "    data_test['AREA'] = y_pred\n",
    "    print(i)\n",
    "    display(data_test.head(2))\n",
    "    print_results(DirectMapping.main(data_test, plot_figure=True))\n",
    "    print()\n",
    "    print_results(results_direct_mapping[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alphas = np.arange(0.1, 10.1, 0.1)\n",
    "scores_train = []\n",
    "scores_test = []\n",
    "X, y = ML.separate_feature_label(data_train, invalid_features=['Slices', 'Latency'], label='Slices')\n",
    "X = ML.feature_scaling(X)\n",
    "for alpha in alphas:\n",
    "#     estimator = linear_model.Lasso(alpha=alpha)\n",
    "#     estimator = linear_model.ElasticNet(alpha=alpha)\n",
    "    estimator = linear_model.Ridge(alpha=alpha)\n",
    "    scores_cv_train, scores_cv_test = [], []\n",
    "    # cross-validation using shuffle split\n",
    "    for train_indices, test_indices in ShuffleSplit(n_splits=5, random_state=42).split(X):\n",
    "        estimator.fit(X[train_indices], y[train_indices])\n",
    "        scores_cv_train.append(estimator.score(X[train_indices], y[train_indices]))\n",
    "        scores_cv_test.append(estimator.score(X[test_indices], y[test_indices]))\n",
    "    scores_train.append(np.mean(scores_cv_train))\n",
    "    scores_test.append(np.mean(scores_cv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, scores_train, 'o-', color='r', label='Training score')\n",
    "plt.plot(alphas, scores_test, 'o-', color='g', label='Cross-validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(cross_val_score(linear_model.BayesianRidge(), X, y, cv=ShuffleSplit(n_splits=10, random_state=42)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "\n",
    "Perform cross-validation on the estimators using all the benchmarks to find the best estimator for the prediction problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = (\n",
    "    linear_model.LinearRegression(),\n",
    "    linear_model.Lasso(),\n",
    "    linear_model.ElasticNet(),\n",
    "    Ridge(),\n",
    "    svm.LinearSVR(random_state=42),\n",
    "    svm.SVR(kernel='linear'),\n",
    "    tree.DecisionTreeRegressor(random_state=42),\n",
    "    ensemble.RandomForestRegressor(random_state=42),\n",
    "    ensemble.AdaBoostRegressor(random_state=42),\n",
    "    ensemble.GradientBoostingRegressor(random_state=42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores_cv = dict()\n",
    "for estimator in estimators:\n",
    "    scores = list()\n",
    "    for benchmark in benchmarks:\n",
    "        score_cv = cross_val_score(estimator, X, y, cv=ShuffleSplit(n_splits=10, random_state=42))\n",
    "        scores.append(np.mean(score_cv))\n",
    "    scores_cv[estimator.__class__] = (np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for estimator in estimators:\n",
    "# estimator = ensemble.GradientBoostingRegressor(random_state=42)\n",
    "    print(estimator.__class__)\n",
    "    selector = RFECV(estimator, step=1, cv=10)\n",
    "    for i in benchmarks:\n",
    "        data = ML.fix_missing_data(gd.data_v4[i][features])\n",
    "        X, y = ML.separate_feature_label(data, invalid_features=invalid_features, label=label)\n",
    "        X = ML.feature_scaling(X)\n",
    "        selector = selector.fit(X, y)\n",
    "        print(i)\n",
    "        print(np.array(valid_features)[selector.support_])\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
